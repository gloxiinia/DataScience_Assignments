{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9729 entries, 0 to 9728\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  9729 non-null   int64 \n",
      " 1   title    9729 non-null   object\n",
      " 2   year     9729 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 228.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "movies_df = pd.read_csv('animes.csv')\n",
    "ratings_df = pd.read_csv('reviews.csv')\n",
    "print(movies_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 title  rating\n",
      "0  Breakfast Club, The     5.0\n",
      "1            Toy Story     1.0\n",
      "2              Jumanji     1.0\n",
      "3         Pulp Fiction     5.0\n",
      "4                Akira     4.5\n"
     ]
    }
   ],
   "source": [
    "userInput = [{'title':'Breakfast Club, The', 'rating':5},\n",
    "             {'title':'Toy Story', 'rating':1},\n",
    "             {'title':'Jumanji', 'rating':1},\n",
    "             {'title':'Pulp Fiction', 'rating':5},\n",
    "             {'title':'Akira', 'rating':4.5}]\n",
    "inputMovies = pd.DataFrame(userInput)\n",
    "print(inputMovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                title  rating\n",
      "0        1            Toy Story     1.0\n",
      "1        2              Jumanji     1.0\n",
      "2      296         Pulp Fiction     5.0\n",
      "3     1274                Akira     4.5\n",
      "4     1968  Breakfast Club, The     5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rache\\AppData\\Local\\Temp/ipykernel_14132/114554541.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  inputMovies = inputMovies.drop('year', 1) #we don't really need this at the moment\n"
     ]
    }
   ],
   "source": [
    "inputId = movies_df[movies_df['title'].isin(inputMovies['title'].tolist())]\n",
    "inputMovies = pd.merge(inputId, inputMovies)\n",
    "inputMovies = inputMovies.drop('year', 1) #we don't really need this at the moment\n",
    "inputMovies = inputMovies[['movieId','title','rating']]\n",
    "print(inputMovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         userId  rating  timestamp\n",
      "movieId                           \n",
      "1           215     215        215\n",
      "2           110     110        110\n",
      "296         307     307        307\n",
      "1274         39      39         39\n",
      "1968        113     113        113\n"
     ]
    }
   ],
   "source": [
    "userSubset = ratings_df[ratings_df['movieId'].isin(inputMovies['movieId'].tolist())]\n",
    "print(userSubset.groupby('movieId').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(91,      userId  movieId  rating   timestamp\n",
      "119      91        1     4.0  1112713037\n",
      "120      91        2     3.0  1112713392\n",
      "121      91      296     4.5  1112711264\n",
      "122      91     1274     5.0  1112713057\n",
      "123      91     1968     3.0  1112713409), (177,      userId  movieId  rating   timestamp\n",
      "242     177        1     5.0  1435533535\n",
      "243     177        2     3.5  1435534109\n",
      "244     177      296     5.0  1435530409\n",
      "245     177     1274     2.0  1435535036\n",
      "246     177     1968     3.5  1435534080), (219,      userId  movieId  rating   timestamp\n",
      "306     219        1     3.5  1194681084\n",
      "307     219        2     2.5  1194740185\n",
      "308     219      296     4.0  1198522553\n",
      "309     219     1274     2.5  1194686351\n",
      "310     219     1968     3.0  1194931899), (274,      userId  movieId  rating   timestamp\n",
      "377     274        1     4.0  1171410158\n",
      "378     274        2     3.5  1171934785\n",
      "379     274      296     5.0  1171493995\n",
      "380     274     1274     4.0  1205707621\n",
      "381     274     1968     4.0  1186729108), (298,      userId  movieId  rating   timestamp\n",
      "425     298        1     2.0  1447518257\n",
      "426     298        2     0.5  1450452897\n",
      "427     298      296     4.5  1447584408\n",
      "428     298     1274     4.0  1476627223\n",
      "429     298     1968     3.5  1466277248)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rache\\AppData\\Local\\Temp/ipykernel_14132/2911040200.py:10: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  userSubsetGroup = sorted(userSubsetGroup, key=take_5_elem, reverse=True)\n"
     ]
    }
   ],
   "source": [
    "#Groupby creates several sub dataframes where they all have the same value in the column specified as the parameter\n",
    "userSubsetGroup = userSubset.groupby(['userId'])\n",
    "\n",
    "def take_5_elem(x):\n",
    "    # print (len(x[1]))\n",
    "    return len(x[1])\n",
    "    \n",
    "\n",
    "#Sorting it so users with movie most in common with the input will have priority\n",
    "userSubsetGroup = sorted(userSubsetGroup, key=take_5_elem, reverse=True)\n",
    "\n",
    "userSubsetGroup = userSubsetGroup[0:100]\n",
    "print(userSubsetGroup[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the Pearson Correlation in a dictionary, where the key is the user Id and the value is the coefficient\n",
    "pearsonCorrelationDict = {}\n",
    "\n",
    "#For every user group in our subset\n",
    "for name, group in userSubsetGroup:\n",
    "\n",
    "    #Let's start by sorting the input and current user group so the values aren't mixed up later on\n",
    "    group = group.sort_values(by='movieId')\n",
    "    inputMovies = inputMovies.sort_values(by='movieId')\n",
    "\n",
    "    #Get the N for the formula\n",
    "    nRatings = len(group)\n",
    "\n",
    "    #Get the review scores for the movies that they both have in common\n",
    "    temp_df = inputMovies[inputMovies['movieId'].isin(group['movieId'].tolist())]\n",
    "\n",
    "    #And then store them in a temporary buffer variable in a list format to facilitate future calculations\n",
    "    tempRatingList = temp_df['rating'].tolist()\n",
    "   \n",
    "    #Let's also put the current user group reviews in a list format\n",
    "    tempGroupList = group['rating'].tolist()\n",
    "   \n",
    "    \n",
    "    #Now let's calculate the pearson correlation between two users, so called, x and y manually (check the formula from week 7 slide)\n",
    "    Sxx = sum([i**2 for i in tempRatingList]) - pow(sum(tempRatingList),2)/float(nRatings)\n",
    "    Syy = sum([i**2 for i in tempGroupList]) - pow(sum(tempGroupList),2)/float(nRatings)\n",
    "    Sxy = sum( i*j for i, j in zip(tempRatingList, tempGroupList)) - sum(tempRatingList)*sum(tempGroupList)/float(nRatings)\n",
    "\n",
    "    #If the denominator is different than zero, then divide, else, 0 correlation.\n",
    "    if Sxx != 0 and Syy != 0:\n",
    "        pearsonCorrelationDict[name] = Sxy/sqrt(Sxx*Syy)\n",
    "    else:\n",
    "        pearsonCorrelationDict[name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   similarityIndex  userId\n",
      "0         0.351124      91\n",
      "1        -0.254967     177\n",
      "2         0.199967     219\n",
      "3         0.616658     274\n",
      "4         0.916619     298\n"
     ]
    }
   ],
   "source": [
    "pearsonDF = pd.DataFrame.from_dict(pearsonCorrelationDict, orient='index')\n",
    "pearsonDF.columns = ['similarityIndex']\n",
    "pearsonDF['userId'] = pearsonDF.index\n",
    "pearsonDF.index = range(len(pearsonDF))\n",
    "print(pearsonDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    similarityIndex  userId\n",
      "49              1.0     160\n",
      "43              1.0     132\n",
      "70              1.0     373\n",
      "82              1.0     489\n",
      "63              1.0     305\n"
     ]
    }
   ],
   "source": [
    "topUsers=pearsonDF.sort_values(by='similarityIndex', ascending=False)[0:50]\n",
    "print(topUsers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    similarityIndex  userId  movieId  rating   timestamp\n",
      "0          1.000000     160        1     4.0   971115026\n",
      "1          1.000000     160        2     4.0   971619578\n",
      "2          1.000000     160      296     5.0   971113194\n",
      "3          1.000000     160     2000     4.0   971116347\n",
      "4          1.000000     132        1     2.0  1157921785\n",
      "..              ...     ...      ...     ...         ...\n",
      "95         0.807395     414        2     3.0   961594981\n",
      "96         0.807395     414      296     5.0   961516693\n",
      "97         0.807395     414     1274     4.0   997200022\n",
      "98         0.807395     414     1968     5.0   961517252\n",
      "99         0.807395     414     2000     3.0   961437472\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "topUsersRating=topUsers.merge(ratings_df, left_on='userId', right_on='userId', how='inner')\n",
    "print(topUsersRating.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   similarityIndex  userId  movieId  rating   timestamp  weightedRating\n",
      "0              1.0     160        1     4.0   971115026             4.0\n",
      "1              1.0     160        2     4.0   971619578             4.0\n",
      "2              1.0     160      296     5.0   971113194             5.0\n",
      "3              1.0     160     2000     4.0   971116347             4.0\n",
      "4              1.0     132        1     2.0  1157921785             2.0\n"
     ]
    }
   ],
   "source": [
    "#Multiplies the similarity by the user’s ratings\n",
    "topUsersRating['weightedRating'] = topUsersRating['similarityIndex']*topUsersRating['rating']\n",
    "print(topUsersRating.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sum_similarityIndex  sum_weightedRating\n",
      "movieId                                         \n",
      "1                  33.529084          114.442383\n",
      "2                  27.842790           87.478362\n",
      "296                35.450198          159.672967\n",
      "1274               10.413839           44.111899\n",
      "1968               25.705969          108.005467\n"
     ]
    }
   ],
   "source": [
    "#Applies a sum to the topUsers after grouping it up by movieId\n",
    "tempTopUsersRating = topUsersRating.groupby('movieId').sum()[['similarityIndex','weightedRating']]\n",
    "tempTopUsersRating.columns = ['sum_similarityIndex','sum_weightedRating']\n",
    "print(tempTopUsersRating.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         weighted average recommendation score  movieId\n",
      "movieId                                                \n",
      "1                                     3.413227        1\n",
      "2                                     3.141868        2\n",
      "296                                   4.504149      296\n",
      "1274                                  4.235892     1274\n",
      "1968                                  4.201571     1968\n",
      "2000                                  3.681548     2000\n",
      "2004                                  3.221759     2004\n",
      "2007                                  3.147320     2007\n"
     ]
    }
   ],
   "source": [
    "#Creates an empty dataframe\n",
    "recommendation_df = pd.DataFrame()\n",
    "\n",
    "#Now we take the weighted average\n",
    "recommendation_df['weighted average recommendation score'] = tempTopUsersRating['sum_weightedRating']/tempTopUsersRating['sum_similarityIndex']\n",
    "recommendation_df['movieId'] = tempTopUsersRating.index\n",
    "print(recommendation_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         weighted average recommendation score  movieId\n",
      "movieId                                                \n",
      "296                                   4.504149      296\n",
      "1274                                  4.235892     1274\n",
      "1968                                  4.201571     1968\n",
      "2000                                  3.681548     2000\n",
      "1                                     3.413227        1\n",
      "2004                                  3.221759     2004\n",
      "2007                                  3.147320     2007\n",
      "2                                     3.141868        2\n"
     ]
    }
   ],
   "source": [
    "recommendation_df = recommendation_df.sort_values(by='weighted average recommendation score', ascending=False)\n",
    "print(recommendation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      movieId                      title  year\n",
      "1475     2000              Lethal Weapon  1987\n",
      "1479     2004  Gremlins 2: The New Batch  1990\n",
      "1482     2007             Polish Wedding  1998\n"
     ]
    }
   ],
   "source": [
    "recommended_movie=movies_df.loc[movies_df['movieId'].isin(recommendation_df['movieId'])]\n",
    "\n",
    "#we don't want to recommend the same movie\n",
    "recommended_movie=recommended_movie.loc[~recommended_movie.movieId.isin(userSubset['movieId'])]\n",
    "\n",
    "print(recommended_movie)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1dcd73c375d9deeda09dd176a4da94734a037bbf84794cec223e301645d05570"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
